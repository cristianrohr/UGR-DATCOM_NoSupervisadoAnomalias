---
title: "Trabajo PrÃ¡ctico"
author: "Cristian Rohr"
date: "31 de enero de 2018"
output:
  pdf_document:
    number_sections: true
---

\newpage
\tableofcontents
\newpage


```{r setup, include=FALSE, results = 'hide', show = FALSE}
knitr::opts_chunk$set(echo = TRUE)
# M?ster -> Detecci?n de anomal?as
# Juan Carlos Cubero. Universidad de Granada

###########################################################################
# Paquetes usados a lo largo del curso
###########################################################################



#Gr?ficos
#install.packages("ggplot2")

library(ggplot2)

#install.packages("devtools")
library(devtools)

#install_github("ggbiplot", "vqv")
library(reshape)   # melt
library(ggbiplot)

#install.packages("rgl")     #plot3D
#library(rgl)  
               
#install.packages("GGally")  #ggpairs
library(GGally)


################################################################################
# 1-variate

#install.packages("outliers")  # Grubb
library(outliers)

#install.packages("EnvStats")  # Rosner
library(EnvStats)

################################################################################

# Multi-variate -Mahalanobis-

#install.packages("mvoutlier")  #MCD ChiC
library(mvoutlier)       

#install.packages("CerioliOutlierDetection")  #MCD Hardin Rocke
#library(CerioliOutlierDetection)

#install.packages("robustbase")
#library(robustbase)

#install.packages("mvnormtest")   # Test Normalidad multivariante
#library(mvnormtest)   

library(MASS) 

################################################################################

# Multivariate Unsupervised

#install.packages("DMwR")  #lof
library(DMwR)

#install.packages("cluster")
library(cluster)    # PAM

library(ggrepel)

# M?ster -> Detecci?n de anomal?as
# Juan Carlos Cubero. Universidad de Granada

###########################################################################
# Funciones utilizadas a lo largo del curso
###########################################################################


rm(list=ls()) 


#######################################################################
# Muestra un plot b?sico con los outliers en rojo
# Necesita como par?metros de entrada:
# el dataset "datos", un vector de T/F indicando si el registro i-?simo 
# de "datos" es o no un outlier (seg?n el m?todo aplicado) 
# y el t?tulo a aparecer en el gr?fico

MiPlot_Univariate_Outliers = function (datos, indices_de_Outliers, titulo){
  numero.de.datos = nrow(as.matrix(datos))
  vectorTFoutliers =  rep(FALSE, numero.de.datos)
  vectorTFoutliers[indices_de_Outliers] = TRUE
  vector.colores.outlier = rep("black", numero.de.datos)
  vector.colores.outlier [vectorTFoutliers] = "red"
  
  cat("\nN?mero de datos: ")
  cat(numero.de.datos)
  cat("\n?Qui?n es outlier?: ")
  cat(vectorTFoutliers)
  cat('\n')
  
  # X11()
  plot(datos, col=vector.colores.outlier, main = titulo)
}



###########################################################################
# Calcula los outliers IQR 
# Devuelve un vector TRUE/FALSE indicando si el registro i-?simo 
# de "datos" es o no un outlier IQR con respecto a la columna de ?ndice "indice"
# coef es 1.5 para los outliers normales y hay que pasarle 3 para los outliers extremos

vector_es_outlier_IQR = function (datos, indice.de.columna, coef = 1.5){
  columna.datos = datos[,indice.de.columna]
  cuartil.primero = quantile(columna.datos)[2]  #quantile[1] es el m?nimo y quantile[5] el m?ximo.
  cuartil.tercero = quantile(columna.datos)[4] 
  iqr = cuartil.tercero - cuartil.primero
  extremo.superior.outlier = (iqr * coef) + cuartil.tercero
  extremo.inferior.outlier = cuartil.primero - (iqr * coef)
  es.outlier  = columna.datos > extremo.superior.outlier |
    columna.datos < extremo.inferior.outlier
  return (es.outlier)
}

vector_claves_outliers_IQR = function(datos, indice, coef = 1.5){
  columna.datos = datos[,indice]
  vector.de.outliers = vector_es_outlier_IQR(datos, indice, coef)
  return (which(vector.de.outliers  == TRUE))
}



#######################################################################
# Devuelve los nombres de aquellas filas de datos especificadas 
# en el segundo par?metro (vector de T/F)

Nombres_de_Filas = function (datos, vector_TF_datos_a_incluir) {
  numero.de.filas = nrow(datos)
  
  if (is.null(row.names(datos)))
    row.names(datos) = rep(1:numero.de.filas)
  
  nombres.de.filas = rep("", numero.de.filas)
  nombres.de.filas[vector_TF_datos_a_incluir==TRUE] = 
        row.names(datos)[vector_TF_datos_a_incluir==TRUE]
  return (nombres.de.filas)
}



#######################################################################
# Calcula los outliers IQR y muestra sus etiquetas en un BoxPlot

MiBoxPlot_IQR_Univariate_Outliers = function (datos, indice.de.columna, coef = 1.5){
  # Importante: Para que aes busque los par?metros en el ?mbito local, 
  # debe incluirse  environment = environment()
  
  datos = as.data.frame(datos)
  vector.TF.outliers.IQR = vector_es_outlier_IQR(datos, indice.de.columna, coef)
  nombres.de.filas = Nombres_de_Filas(datos, vector.TF.outliers.IQR)
  nombre.de.columna = colnames(datos)[indice.columna]
  
  ggboxplot = ggplot(data = datos, 
                     aes(x=factor(""), 
                     y=datos[,indice.de.columna]) , 
                     environment = environment()) + 
    xlab(nombre.de.columna) + ylab("") +
    geom_boxplot(outlier.colour = "red") + 
    geom_text_repel(aes(label = nombres.de.filas)) #, position = position_jitter(width = 0.1))   
  
  # X11()
  ggboxplot
}



#######################################################################
# Muestra de forma conjunta todos los BoxPlots de las columnas de datos
# Para ello, normaliza los datos.
# Tambi?n muestra con un punto en rojo los outliers de cada columna
# Requiere reshape


MiBoxPlot_juntos  = function (datos, vector_TF_datos_a_incluir = c()){  
  # Importante: Para que aes busque los par?metros en el ?mbito local, 
  # debe incluirse  environment = environment()
  
  # Para hacerlo con ggplot, lamentablemente hay que construir antes una tabla 
  # que contenga en cada fila el valor que a cada tupla le da cada variable 
  # -> paquete reshape->melt
  
  # Por ejemplo, si tenemos el siguiente data frame
  
  # datos = data.frame(
  #   A  = c(1, 2),
  #   B = c(3, 4)
  # )
  # datos =
  #     A  B
  #     1  3
  #     2  4
  
  # melt(datos) construye esta tabla:
  
  #      variable value
  # 1        A     1
  # 2        A     2
  # 3        B     3
  # 4        B     4

  
  nombres.de.filas = Nombres_de_Filas(datos, vector_TF_datos_a_incluir)
  
  datos = scale(datos)
  datos.melted = melt(datos)
  colnames(datos.melted)[2]="Variables"
  colnames(datos.melted)[3]="zscore"
  factor.melted = colnames(datos.melted)[1]
  columna.factor = as.factor(datos.melted[,factor.melted])
  levels(columna.factor)[!levels(columna.factor) %in% nombres.de.filas] = ""  
  
  ggplot(data = datos.melted, aes(x=Variables, y=zscore), environment = environment()) + 
    geom_boxplot(outlier.colour = "red") + 
    geom_text(aes(label = columna.factor), size = 3) 
}



#######################################################################
# Muestra de forma conjunta todos los BoxPlots de las columnas de datos
# Para ello, normaliza los datos
# Tambi?n muestra las etiquetas de los outliers de cada columna


MiBoxPlot_juntos_con_etiquetas = function (datos, coef = 1.5){
  # Aplicamos outlier IQR a cada columna
  
  matriz.datos.TF.outliers = 
    sapply(1:ncol(datos), function(x) vector_es_outlier_IQR(datos, x, coef))  
  
  vector.datos.TF.outliers = apply(matriz.datos.TF.outliers, 1, sum)   
  vector.datos.TF.outliers[vector.datos.TF.outliers > 1] = 1 # Si un registro es outlier en alguna columna lo incluimos
  
  MiBoxPlot_juntos(datos, vector.datos.TF.outliers)
}



#######################################################################
# Aplica el test de Grubbs e imprime los resultados

MiPlot_resultados_TestGrubbs = function(datos){
  alpha = 0.05
  
  test.de.Grubbs = grubbs.test(datos, two.sided = TRUE)
  cat('p.value: ')
  cat(test.de.Grubbs$p.value)
  cat('\n')
  
  if (test.de.Grubbs$p.value < alpha){
    indice.de.outlier.Grubbs = order(abs(datos - mean(datos)), decreasing = T)[1]
    indice.de.outlier.Grubbs
    cat('?ndice de outlier: ')
    cat(indice.de.outlier.Grubbs)
    cat('\n')
    valor.de.outlier.Grubbs  = datos[indice.de.outlier.Grubbs]
    cat('Valor del outlier: ')
    cat(valor.de.outlier.Grubbs)
    MiPlot_Univariate_Outliers (datos, indice.de.outlier.Grubbs, "Test de Grubbs")
  }
  else
    cat('No hay outliers')
}


#######################################################################
# Aplica el test de Rosner e imprime los resultados

MiPlot_resultados_TestRosner = function(datos){  
  test.de.rosner = rosnerTest(datos, k=4)
  is.outlier.rosner = test.de.rosner$all.stats$Outlier
  k.mayores.desviaciones.de.la.media = test.de.rosner$all.stats$Obs.Num
  indices.de.outliers.rosner = k.mayores.desviaciones.de.la.media[is.outlier.rosner]
  valores.de.outliers.rosner = datos[indices.de.outliers.rosner]
  
  cat("\nTest de Rosner")
  cat("\n?ndices de las k-mayores desviaciones de la media: ")
  cat(k.mayores.desviaciones.de.la.media)
  cat("\nDe las k mayores desviaciones, ?Qui?n es outlier? ")
  cat(is.outlier.rosner)
  cat("\nLos ?ndices de los outliers son: ")
  cat(indices.de.outliers.rosner)
  cat("\nLos valores de los outliers son: ")
  cat(valores.de.outliers.rosner)
  
  MiPlot_Univariate_Outliers (datos, indices.de.outliers.rosner, "Test de Rosner")
}


MiBiplot = function(datos){
  PCA.model = princomp(scale(datos))
  biplot = ggbiplot(PCA.model, obs.scale = 1, var.scale=1 , varname.size = 5,alpha = 1/2) 
  # X11()
  print(biplot)
}

MiBiPlot_Multivariate_Outliers = function (datos, vectorTFoutliers, titulo){
   identificadores_de_datos = rownames(datos)
   identificadores_de_datos[!vectorTFoutliers] = ''
   cat(identificadores_de_datos)
 
   PCA.model = princomp(scale(datos))
   outlier.shapes = c(".","x") #c(21,8)
   biplot = ggbiplot(PCA.model, 
                     obs.scale = 1, 
                     var.scale=1 , 
                     varname.size = 5,
                     groups =  vectorTFoutliers, 
                     alpha = 1/2) #alpha = 1/10
   biplot = biplot + labs(color = "Outliers")
   biplot = biplot + scale_color_manual(values = c("black","red"))
   biplot = biplot + geom_text(label = identificadores_de_datos, 
                               stat = "identity", 
                               size = 3, 
                               hjust=0, 
                               vjust=0)
   biplot = biplot + ggtitle(titulo)
  
   # X11()
   print(biplot)
}


# Dentro de MiBiPlot_Clustering_Outliers se llama a la funci?n ggbiplot, la cual est? basada
# en la funci?n ggplot que tiene un bug de dise?o ya que dentro del par?metro aes
# s?lo se pueden llamar a variables del entorno global y no del entorno local.
# Por tanto, desgraciadamente, debemos establecer variables globales que 
# son usadas dentro de nuestra funci?n MiBiPlot_Clustering_Outliers:
# BIPLOT.isOutlier
# BIPLOT.asignaciones.clusters
# BIPLOT.cluster.colors

MiBiPlot_Clustering_Outliers = function (datos, titulo){
  PCA.model = princomp(scale(datos))
  outlier.shapes = c("o","x") #c(21,8)
  
  identificadores_de_datos = rownames(datos)
  identificadores_de_datos[!BIPLOT.isOutlier] = ''
  #cat(identificadores_de_datos)
  
  BIPLOT.asignaciones.clusters = factor(BIPLOT.asignaciones.clusters)
  
  biplot = ggbiplot(PCA.model, obs.scale = 1, var.scale=1 , varname.size = 3, alpha = 0) +              
    geom_point(aes(shape = BIPLOT.isOutlier, colour = factor(BIPLOT.asignaciones.clusters)))  +
    scale_color_manual(values = BIPLOT.cluster.colors) +
    scale_shape_manual(values = outlier.shapes) +
    ggtitle(titulo) +
    geom_text(label = identificadores_de_datos, stat = "identity", size = 3, hjust=0, vjust=0)      
  
  # X11()
  print(biplot)
}




```

# UNIVARIATE STATISTICAL OUTLIERS -> IQR

DetecciÃ³n heurÃ­stica de Outliers en 1 variable segÃºn el mÃ©todo IQR.

Voy a trabajar con el set de datos _**PimaIndiansDiabetes**_ (https://data.world/uci/pima-indians-diabetes).

**Nota: Dejo el codigo utilizado para cargar y preprocesar el dataset, para que se comprenda el contenido final del mismo.**

```{r load, message = FALSE, echo = FALSE}
# Carga del set de datos
library(mlbench)
data(PimaIndiansDiabetes)
mydata.numeric <- PimaIndiansDiabetes 
# Examino la estructura del dataset
str(mydata.numeric)
```

Me quedo con las siguientes columnas: 2-7

Cada columna tiene el siguiente significado:

- Plasma glucose concentration a 2 hours in an oral glucose tolerance test 
- Diastolic blood pressure (mm Hg) 
- Triceps skin fold thickness (mm) 
- 2-Hour serum insulin (mu U/ml) 
- Body mass index (weight in kg/(height in m)^2) 
- Diabetes pedigree function

**Nota:** Los valores codificados como 0 corresponden a missing data. Eliminare las observaciones con valores faltantes en alguna de sus columnas.

```{r preproc2}
# Selecciono las columnas de interes
mydata.numeric  = mydata.numeric[, c(2:7)]

# Recodifico 0 como NA
is.na(mydata.numeric) <- !mydata.numeric
# Elimino filas con missing data
mydata.numeric <- mydata.numeric[complete.cases(mydata.numeric), ]

# Asigno nombre a las filas. Agrego el prefijo 'S'
nombres <- paste("S", seq(1:nrow(mydata.numeric)), sep = "")
rownames(mydata.numeric) <- nombres

# Columna sobre la que trabajare
indice.columna  = 4 # insulin
nombre.mydata   = "pima"
```

PreparaciÃ³n de datos

```{r prep}
mydata.numeric.scaled = scale(mydata.numeric) # Normalizo
columna         = mydata.numeric[, indice.columna] # Me quedo con la columna de interÃ©s
nombre.columna  = names(mydata.numeric)[indice.columna] # Nombre de la columna de interÃ©s
columna.scaled  = mydata.numeric.scaled[, indice.columna] # Columna de interÃ©s normalizada

# Backups de datos
mydata.numeric.backup <- mydata.numeric
mydata.numeric.scaled.backup <- mydata.numeric.scaled
```


## Parte primera. CÃ³mputo de los outliers IQR

### Calcular los outliers segÃºn la regla IQR. Directamente sin funciones propias

```{r 1ero}
quantiles <- quantile(columna, c(0.25, 0.5, 0.75)) # Obtengo cuantiles
cuartil.primero <- quantiles[1] # Primer cuartil
cuartil.tercero <- quantiles[3] # Tercer cuartil
iqr <- cuartil.tercero - cuartil.primero # Rango intercuartil

# Valor de corte superior para outliers normales
extremo.superior.outlier.normal  = cuartil.tercero + 1.5*iqr 
# Valor de corte inferior para outliers normales
extremo.inferior.outlier.normal  = cuartil.primero - 1.5*iqr 
# Valor de corte superior para outliers extremos
extremo.superior.outlier.extremo = cuartil.tercero + 3*iqr 
# Valor de corte inferior para outliers extremos
extremo.inferior.outlier.extremo = cuartil.primero - 3*iqr 

vector.es.outlier.normal <- ifelse(columna < extremo.inferior.outlier.normal, 
                                   TRUE,
                                   ifelse(columna > extremo.superior.outlier.normal,
                                          TRUE, FALSE))

print("Total de observacioness")
length(vector.es.outlier.normal) # Total de observaciones
```

Â¿Cuantos outliers normales hay?

Hay `r sum(vector.es.outlier.normal)` outliers normales.

Â¿Cuantos outliers extremos hay?
```{r 1erob}
vector.es.outlier.extremo <- ifelse(columna < extremo.inferior.outlier.extremo,
                                    TRUE,
                                    ifelse(columna > extremo.superior.outlier.extremo,
                                           TRUE, FALSE))
```

Hay `r sum(vector.es.outlier.extremo)` outliers extremos.

Se calcularon los valores de corte para definir si una observaciÃ³n es un outlier o no. Definimos outliers normales como aquellos que estan por fuera del rango definido por: [1er cuartil - 1.5*IQR, 3er cuartil + 1.5*IQR], donde IQR es el rango intercuartil.

Los outliers extremos son aquellos fuera del rango [1er cuartil - 3*IQR, 3er cuartil + 3*IQR].

Se crearon vectores booleanos que indican si cada observaciÃ³n es un outlier normal u extemo. Y se calculo el total de observaciones que son outliers normales y extremos.

## Ãndices y valores de los outliers

**Outliers normales**

```{r 2do}
claves.outliers.normales <- which(vector.es.outlier.normal)
claves.outliers.normales
```

Obtuvimos los Ã­ndices del vector de aquellos valores que son outliers normales para la columna _insulin_.

```{r 2doa}
data.frame.outliers.normales <- mydata.numeric[claves.outliers.normales, ]
data.frame.outliers.normales
```

Mostramos un dataframe con las muestras que son outliers normales para la columna _insulin_.

```{r 2dob}
nombres.outliers.normales <- row.names(data.frame.outliers.normales)
nombres.outliers.normales
```

Mostramos el nombre de las muestras que son outliers normales para la columna _insulin_.

```{r 2doc}
valores.outliers.normales <- mydata.numeric[vector.es.outlier.normal, nombre.columna]
valores.outliers.normales
```

Mostramos los valores que son outliers normales para la columna _insulin_.

Con los comandos anteriores obtuve los Ã­ndices (nÃºmero de fila) de los outliers normales, un dataframe que contiene las filas que tienen los outliers normales, los nombres de las muestras con los outliers normales y los valores de los outliers normales.

**Outliers extremos**

```{r 2dod}
claves.outliers.extremos <- which(vector.es.outlier.extremo)
claves.outliers.extremos
```

```{r 2doe}
data.frame.outliers.extremos <- mydata.numeric[vector.es.outlier.extremo, ]
data.frame.outliers.extremos
```

```{r 2dof}
nombres.outliers.extremos <- row.names(data.frame.outliers.extremos)
nombres.outliers.extremos
```

```{r 2dog}
valores.outliers.extremos <- mydata.numeric[vector.es.outlier.extremo, nombre.columna]
valores.outliers.extremos
```

Con los comandos anteriores obtuve los Ã­ndices (nÃºmero de fila) de los outliers extremos, un dataframe que contiene las filas que tienen los outliers extremos, los nombres de las muestras con los outliers extremos y los valores de los outliers extremos.


## DesviaciÃ³n de los outliers con respecto a la media de la columna
```{r 3ro}
valores.normalizados.outliers.normales <- columna.scaled[vector.es.outlier.normal]
valores.normalizados.outliers.normales
```

Me fijo cuanto se desvian los outliers con respecto a la media de la columna. Recordar que los datos fueron normalizados con un Z-score.

Repito paralos outliers extremos
```{r 3rob}
valores.normalizados.outliers.extremos <- columna.scaled[vector.es.outlier.extremo]
valores.normalizados.outliers.extremos
```


## Plot
```{r 4to}
# Primero lo hago con los datos sin normalizar
# outliers normales
MiPlot_Univariate_Outliers(columna, claves.outliers.normales, nombre.columna) 
# outliers extremos
MiPlot_Univariate_Outliers(columna, claves.outliers.extremos, nombre.columna) 

# Repito con los datos normalizados
# Outliers normales
MiPlot_Univariate_Outliers(columna.scaled, claves.outliers.normales, nombre.columna)
# Outliers extremos
MiPlot_Univariate_Outliers(columna.scaled, claves.outliers.extremos, nombre.columna)
```

GrÃ¡fico de puntos, de los Ã­ndices vs el valor. 
Se pueden observar a los outliers marcados en color rojo (tanto extremos como normales, dependiendo del grÃ¡fico).

Al observar el grÃ¡fico normalizado y no normalizado son iguales, cambia la escala del eje Y, pero no la distancia entre los datos. La normalizaciÃ³n no afecta la posiciÃ³n de los datos.

## Boxplot

```{r 5to}
# Outliers normales
# Datos sin normalizar
plot.out.normales.sinnormalizar <- MiBoxPlot_IQR_Univariate_Outliers(datos = mydata.numeric,
                                  indice.de.columna = indice.columna, 
                                  coef = 1.5) 
plot.out.normales.sinnormalizar <- plot.out.normales.sinnormalizar + 
  ggtitle("Outliers normales, sin normalizar")
plot.out.normales.sinnormalizar

# Datos Normalizados
plot.out.normales.normalizados <- MiBoxPlot_IQR_Univariate_Outliers(mydata.numeric.scaled, 
                                  indice.columna, 
                                  coef = 1.5) 

plot.out.normales.normalizados <- plot.out.normales.normalizados + 
  ggtitle("Outliers normales, normalizados")
plot.out.normales.normalizados

# Outliers extremos
# Para ver los outliers extremos, debo setear el coeficiente en 3
# Datos sin normalizar
plot.out.extremos.sinnormalizar <- MiBoxPlot_IQR_Univariate_Outliers(datos = mydata.numeric, 
                                  indice.de.columna = indice.columna, 
                                  coef = 3)
plot.out.extremos.sinnormalizar <- plot.out.extremos.sinnormalizar + 
  ggtitle("Outliers extremos, sin normalizar")
plot.out.extremos.sinnormalizar

# Datos normalizados
plot.out.extremos.normalizados <- MiBoxPlot_IQR_Univariate_Outliers(mydata.numeric.scaled, 
                                  indice.columna,
                                  coef = 3)
plot.out.extremos.normalizados <- plot.out.extremos.normalizados + 
  ggtitle("Outliers extremos, normalizados")
plot.out.extremos.normalizados
```

GrÃ¡ficos de caja para outliers normales (datos sin normalizar y normalizados) y para outliers extremos (datos normalizados y sin normalizar).

Cuando comparo los datos normalizados y no normalizados, vemos que el Boxplot es el mismo ya que la normalizaciÃ³n no afecta a la posiciÃ³n relativa de los datos. Se pueden observar como los outliers estan por fuera de la caja que marca el comienzo y fin del 1er y 3er cuartil, y de la lÃ­nea solida que continua, que marca el punto a partir del cual nos alejamos 1.5 veces del rango intercuartil

**Nota: Hize una modificaciÃ³n a la funciÃ³n entregada en clase, para usar geom_text_repel del paquete ggrepel en lugar de geom_text, para evitar la superposiciÃ³n de las etiquetas.**


## CÃ³mputo de los outliers IQR con funciones propias

```{r 6to}
# Outliers normales
print("Vector booleano que indica si un valor es outlier normal")
vector_es_outlier_IQR(datos = mydata.numeric,
                      indice.de.columna = indice.columna, 
                      coef = 1.5)  
print("\n")
print("Ãndices de los outliers normales")
# Outliers normales
vector_claves_outliers_IQR(mydata.numeric, indice.columna, coef = 1.5)

print("\n")
print("Vector booleano que indica si un valor es outlier extremo")
# Outliers extremos
vector_es_outlier_IQR(mydata.numeric, indice.columna, coef = 3) 
print("\n")
print("Ãndices de los outliers extremos")
# Outliers extremos
vector_claves_outliers_IQR(mydata.numeric, indice.columna, coef = 3)

```

La funciÃ³n vector_es_outlier_IQR devuelve un vector de booleanos indicando si un dato es outlier o no, en una determinada columna de un dataframe, de acuerdo a un coeficiente aplicado al rango intercuartil. Si el parÃ¡metro **coef** es 1.5 calculamos los llamados outliers normales, si es 3 los llamados outliers extremos.

La funciÃ³n vector_claves_outliers_IQR retorna los Ã­ndices de los outliers, nuevamente depende del parÃ¡metro **coef** calcularemos los outliers normales o extremos.

## BoxPlot 2
```{r 7to}
# Outliers normales
MiBoxPlot_juntos(mydata.numeric)  
MiBoxPlot_juntos_con_etiquetas(mydata.numeric)
MiBoxPlot_juntos(mydata.numeric, vector.es.outlier.normal)
```

**Nota**: la funciÃ³n MiBoxPlot_juntos etiqueta los outliers, si se le pasa el vector booleano de outliers

Todos los outliers para _Insulin_ no son outliers para otras variables como _glucose_, _pressure_ o _triceps_.

Podemos observar que la muestra _S120_ es un outlier extremo para _Insulin_ y tambien es un outlier para _mass_.

La muestra _S111_ es un outlier extremo para _Insulin_ y tambien es un outlier para _pedigree_, todo parece indicar que tambiÃ©n es un outlier extremo para dicha variable.


# Trabajo sobre varias columnas

Los outliers seguirÃ¡ siendo univariados, pero trabajo sobre varias columnas al mismo tiempo.

```{r 8vo}
indices.de.outliers.en.alguna.columna <- unlist(sapply(1:ncol(mydata.numeric), 
                                                       vector_claves_outliers_IQR, 
                                                       datos = mydata.numeric, 
                                                       coef = 1.5 )
                                                )
# Ãndices de outliers en alguna columna
indices.de.outliers.en.alguna.columna
# Obtenemos las filas Ãºnicas con outliers en al menos 1 columna
length(unique(indices.de.outliers.en.alguna.columna))
```

Hay `r length(unique(indices.de.outliers.en.alguna.columna))` filas con outliers en al menos una de las columnas

Chequeo la cantidad de outliers extremos en alguna columna
```{r 8vob}
indices.de.outliers.extremos.en.alguna.columna <- unlist(sapply(1:ncol(mydata.numeric), 
                                                       vector_claves_outliers_IQR, 
                                                       datos = mydata.numeric, 
                                                       coef = 3 )
)

# Ãndices de outliers extremos en alguna columna
indices.de.outliers.extremos.en.alguna.columna
# Obtenemos las filas Ãºnicas con outliers en al menos 1 columna
length(unique(indices.de.outliers.extremos.en.alguna.columna))
```

En total `r length(unique(indices.de.outliers.extremos.en.alguna.columna))` filas tienen outliers extremos en almenos 1 de las columnas

```{r 8voc}
mydata.numeric.scaled[indices.de.outliers.extremos.en.alguna.columna, ]
```

Arriba vemos el dataframe de valores normalizados, de las muestras que son outlier extremo en alguna de las columnas. Podemos observar el caso de la muestra _S87_ que se dispara mucho tanto en la columna _mass_ como _pressure_. O el de la _S111_ que se dispara en _pedigree_ e _insulin_.

**Nota: no mostre los outliers normales en alguna columna, para no generar un dataframe de `r length(unique(indices.de.outliers.en.alguna.columna))` filas**


Construyo una funciÃ³n que devuelve un vector de Ã­ndices de aquellos registros que tienen un outlier en alguna de las columnas
```{r 8vod}
vector_claves_outliers_IQR_en_alguna_columna <- function(datos, coef = 1.5) {
  indices <- unlist(sapply(1:ncol(datos), 
    vector_claves_outliers_IQR, 
    datos = datos, 
    coef = 1.5 )
  )
  indices
}

indices.de.outliers.en.alguna.columna.funcion <- vector_claves_outliers_IQR_en_alguna_columna(mydata.numeric)

# Chequeo que coincidan los valores
if(sum(indices.de.outliers.en.alguna.columna == indices.de.outliers.en.alguna.columna.funcion))
{
  print("Coincidencia. FunciÃ³n bien implementada.")
} else {
  print("Hay algo mal. Chequear la implementaciÃ³n de la funciÃ³n")
}
```

La funciÃ³n esta implementada correctamente

FunciÃ³n que devuelve un vector booleano indicando si una muestra en outlier en alguna columna
```{r 8voe}
vector_es_outlier_IQR_en_alguna_columna = function(datos, coef = 1.5){
  indices.de.outliers.en.alguna.columna =  vector_claves_outliers_IQR_en_alguna_columna(datos, coef)
  todos = c(1:nrow(datos))
  bools = todos %in% indices.de.outliers.en.alguna.columna
  return (bools)
}

outliers.en.alguna.columna.funcion <- vector_es_outlier_IQR_en_alguna_columna(mydata.numeric)
outliers.en.alguna.columna.funcion
```






# UNIVARIATE STATISTICAL OUTLIERS -> 1-variate Normal Distribution

DetecciÃ³n de Outliers en 1 variable normal aplicando tests estadÃ­sticos paramÃ©tricos.

Genero datos con un outlier, para esto voy a tomar los valores de la columna Insulin del dataset pima,
voy a quedarme con el outlier mas extremo, y remover el resto de outlier calculados en los puntos anteriores, ademÃ¡s de downsamplear los datos.

**Nota: Dejo el codigo utilizado para que se comprenda lo que realize.**
  
```{r B2_1a}
aux <- columna # Columna tiene los valores de Insulin
maximo <- max(columna) # Me quedo con el maximo

# El vector.es.outlier.normal es un vector TRUE/FALSE con los datos de que valor es outlier
vector.es.outlier.normal.aux <- vector.es.outlier.normal
names(vector.es.outlier.normal.aux) <- rownames(mydata.numeric.backup)

# Elimino los outliers
aux <- aux[!vector.es.outlier.normal.aux]

# Hago un downsample a 14 elementos
set.seed(87)
aux <- sample(x = aux, size = 14, replace = F)

# Agrego el valor outlier maximo
aux <- c(aux, maximo)

# Ahora si tengo mis datos para trabajar
datos.con.un.outlier <- aux
mydata.numeric = datos.con.un.outlier
max(mydata.numeric)
```


```{r B2_1}
hist(mydata.numeric)
plot(mydata.numeric)
```

Mostramos el histograma de mydata.numeric usando la funciÃ³n hist y un grÃ¡fico de puntos con la funciÃ³n plot.

Observamos que hay un dato con un valor extremo, que es el outlier mas extremo que deje intencionalmente.

```{r B2_2}
test.de.Grubbs <- grubbs.test(mydata.numeric, two.sided = TRUE)
test.de.Grubbs
test.de.Grubbs$p.value
```

El test de Grubb's es un test estadÃ­stico usado para detectar outliers en un data set univariado, en el cual se asume que los datos vienen de una poblaciÃ³n normalmente distribuida.

El test es capaz de detectar un outlier a la vez.

Las hipÃ³tesis que se testean son las siguientes:

- Ho: No hay outliers en los datos
- Ha: Hay exactamente un outlier en los datos.

El p-valor 1.995367E-05 es significativo con los valores de alpha usuales 0.025, 0.01. Por lo tanto rechazamos la hipÃ³tesis nula de que no hay outliers en los datos y aceptamos la hipÃ³tesis alternativa de que hay 1 outlier en los datos (el valor `r outlier(mydata.numeric)`).

```{r B2_3}
valor.de.outlier.Grubbs <- outlier(mydata.numeric)
valor.de.outlier.Grubbs
indice.de.outlier.Grubbs <- which(mydata.numeric == valor.de.outlier.Grubbs)
indice.de.outlier.Grubbs
```

Obtuvimos el valor del outlier con la funciÃ³n _outlier_, luego obtuvimos el Ã­ndice del outlier chequeando cual Ã­ndice se corresponde con el valor obtenido.

```{r B2_4}
MiPlot_Univariate_Outliers(mydata.numeric, indice.de.outlier.Grubbs, "Outlier test de Grubbs")
```

La funciÃ³n MiPlot_Univariate_Outliers grafica los datos y marca el outlier con color rojo. Para esto toma como parÃ¡metros los datos y un vector booleano indicando el valor/es outlier.

## El mismo proceso anterior empaquetado en una funciÃ³n 

```{r B2_5}
MiPlot_resultados_TestGrubbs(mydata.numeric)
```

La funciÃ³n MiPlot_resultados_TestGrubbs aplica el test de Grubbs y grafica los resultados. AdemÃ¡s muestra por pantalla el p-valor del test, 1.995367E-05 en este caso, el Ã­ndice del valor outlier detectado, el valor del mismo, y un vector booleano indicando cada indice si es outlier o no.


Genero dos nuevos vectores, uno con dos outliers y otro con varios outliers

```{r B2_6}
# Agrego un nuevo outlier
datos.con.dos.outliers.masking <- c(mydata.numeric, (max(mydata.numeric) - 50))
# Datos con varios outliers
datos.con.varios.outliers <- columna
```

## Datos.con.dos.outliers.masking
```{r B2_7}
plot(datos.con.dos.outliers.masking)
test.de.Grubbs <- grubbs.test(datos.con.dos.outliers.masking, two.sided = TRUE)
test.de.Grubbs$p.value
test.de.Grubbs
```

El resultado no es significativo, pvalor: 0.06436966, el test no fue capaz de encontrar un outlier.
Sufrimos el efecto de masking. La presencia de dos outliers mueve la media y el desvio estandar hacia ellos, haciendo que el estadÃ­stico no pueda detectarlos como outliers.


## Datos con varios outliers
```{r B2_7b}
plot(datos.con.varios.outliers)
test.de.Grubbs <- grubbs.test(datos.con.varios.outliers)
test.de.Grubbs$p.value
test.de.Grubbs
```

El test fue capaz de detectar un valor outlier, pvalor: 5.814236E-07, el outlier es el valor 846. Sin embargo en este caso tenÃ­amos varios outliers y el test solo nos informa la presencia de uno. Lo que se puede realizar es iterativamente ir eliminando el valor outlier y probando nuevamente hasta que el test no detecte la presencia de outliers.

## Test de Rosner

El test de Rosner permite detectar un nÃºmero de outliers menor o igual a un valor determinado.

En este caso vamos a probar con un valor de 4.
```{r B2_8}
test.de.rosner <- rosnerTest(datos.con.dos.outliers.masking, k = 4)
test.de.rosner$all.stats$Outlier 
test.de.rosner$all.stats$Obs.Num
indices.outliers <- test.de.rosner$all.stats$Obs.Num[test.de.rosner$all.stats$Outlier]

MiPlot_Univariate_Outliers(datos.con.dos.outliers.masking,
indices.outliers,
"Datos con dos outliers")

```

El test es capaz de detectar los dos outliers presentes en los datos. Luego le pasamos los Ã­ndices de los outliers a la funciÃ³n MiPlot_Univariate_Outliers para graficar los datos y marcar en rojo los outliers.

```{r B2_9}
MiPlot_resultados_TestRosner(datos.con.dos.outliers.masking)
```

La funciÃ³n MiPlot_resultados_TestRosner automatiza la ejecuciÃ³n del test de Rosner y el grÃ¡fico de resultados.
AdemÃ¡s nos informa la siguiente informaciÃ³n reelevante:

- Ãndices de las observaciones con mayor desviaciÃ³n
- Vector booleano indicando cuales de los Ã­ndices anterior son outliers.
- Ãndices de los outliers
- Valores de los outliers
- NÃºmero de datos analizados
- Vector booleano indicando para todos los datos analizados cuales son outliers.

```{r B2_10}
MiPlot_resultados_TestRosner(datos.con.un.outlier)
```

Resultados de la funcion sobre el set de datos que tenÃ­a un Ãºnico outlier, podemos observar como el test de Rosner lo identifica de forma Ã³ptima.


```{r B2_11}
plot(datos.con.varios.outliers)
test.de.rosner <- rosnerTest(datos.con.varios.outliers, k = 4)
test.de.rosner$all.stats$Outlier 
test.de.rosner$all.stats$Obs.Num
# Ãndices de los outliers
indices.outliers <- test.de.rosner$all.stats$Obs.Num[test.de.rosner$all.stats$Outlier]
indices.outliers
# Valores de los outliers
datos.con.varios.outliers[indices.outliers]
```

En este caso al tener varios outliers el dataset, el test de Rosner es capaz de encontrar 4, ya que estamos probando la hipÃ³tesis de que el dataset tiene 4 o menos outliers. Los valores de los outliers son `r datos.con.varios.outliers[indices.outliers]`

Voy a probar con un valor de 30, la idea es ver si puedo encontrar los 25 outliers que fueron encontrados con el mÃ©todo IQR.

```{r B2_11b}
test.de.rosner <- rosnerTest(datos.con.varios.outliers, k = 30)
test.de.rosner$all.stats$Outlier 
test.de.rosner$all.stats$Obs.Num
indices.outliers <- test.de.rosner$all.stats$Obs.Num
```

Se encuentran 17 outliers, se recibe una advertencia, que no se calcula el error para valores de k > 10


# MULTIVARIATE STATISTICAL OUTLIERS -> Multivariate Normal Distribution --> Mahalanobis

DetecciÃ³n de Outliers multivariantes en distribuciones conjuntas normales aplicando tests basados en la distancia de Mahalanobis

## ObtenciÃ³n de los outliers multivariantes

```{r C1_1}
# Me quedo con 4 columnas del dataset: glucose, triceps, mass y pressure.
mydata.numeric <- mydata.numeric.backup[,
colnames(mydata.numeric.backup) 
%in%
c("glucose", "triceps", "mass", "pressure")]
mydata.numeric.scaled <- mydata.numeric.scaled.backup[,
colnames(mydata.numeric.scaled.backup) 
%in%
c("glucose", "triceps", "mass", "pressure")]

set.seed(12)
mvoutlier.plot <- uni.plot(mydata.numeric, symb = FALSE, alpha = 0.05)
mvoutlier.plot$outliers

```

La funciÃ³n uni.plot obtiene los outliers calculando las distancias de Mahalanobis y usando la aproximaciÃ³n de la Chi cuadrado.

La estimaciÃ³n de la matriz de covarianzas es la estimaciÃ³n robusta segÃ³n MCD (minimum covariance determinant).

No hay que normalizar los datos ya que la distancia de Mahalanobis estÃ¡ diseÃ±ada, precisamente para evitar el problema de la escala.

El grafico nos muestra los outliers univariantes para cada columna del dataset, pero sin su etiqueta.


```{r C1_2}
is.MCD.outlier <- mvoutlier.plot$outliers
numero.de.outliers.MCD <- length(mvoutlier.plot$outliers[mvoutlier.plot$outliers == TRUE])
indices.de.outliers.multivariantes.MCD <- which(mvoutlier.plot$outliers == TRUE)
```

El dataset tiene `r numero.de.outliers.MCD` outliers multivariantes segun el calculo de la distancia de Mahalanobis.

Las siguientes observaciones son outliers multivariantes:

```{r C1_3a}
indices.de.outliers.multivariantes.MCD
```

Obtenemos los valores normalizados para los outliers multivariantes y mostramos un boxplots con las muestras etiquetadas.
```{r C1_3}
data.frame.solo.outliers <- mydata.numeric.scaled[is.MCD.outlier, ]
data.frame.solo.outliers
MiBoxPlot_juntos(mydata.numeric.scaled, is.MCD.outlier)  
```

A partir de la inspecciÃ³n del dataframe que nos indica que muestras son outliers multivariantes, podemos aprecir cual es el valor que mÃ¡s contribuye a ser un outlier en cada muestra, considerando que observamos el desvÃ­o del valor con respecto a la media. AÃºn asi, hay casos en que es complicado distinguir la relaciÃ³n entre variables que genera el outlier multivariante.

Al observar los boxplots podemos discernir que muchas muestras son outliers multivariantes porque tambien son univariantes, pero hay muestras como ser S124 que no es un outlier univariante para ninguna variable, sin embargo es un outlier multivariante. Siendo en la variable _glucose_ donde es mas extremo.

```{r C1_4}
MiBiPlot_Multivariate_Outliers(mydata.numeric.scaled, is.MCD.outlier, "biplot outliers")
```

Observando el biplot podemos llegar a la misma conclusiÃ³n con respecto a la muestra S124. No es un outlier univariante para ninguna columna, sino que es la combinaciÃ³n de valores para diferentes variables lo que lo convierte en outlier. 

El biplot explica casi el 75% de la variabilidad de los datos.

```{r C1_5}
indices.de.outliers.en.alguna.columna <- vector_claves_outliers_IQR_en_alguna_columna(mydata.numeric)

indices.de.outliers.multivariantes.MCD.pero.no.1variantes <- setdiff(indices.de.outliers.multivariantes.MCD,
indices.de.outliers.en.alguna.columna)
indices.de.outliers.multivariantes.MCD.pero.no.1variantes
```

Podemos observar que los Ã­ndices `r indices.de.outliers.multivariantes.MCD.pero.no.1variantes` se corresponden a dichas muestras son outliers multivariantes, pero no univariantes en ninguna de las 4 columnas analizadas. Es decir que si miramos cada columna por separado, estos cuatro valores no seran outliers en ninguna de ellas, pero la combinacion de valoers en diferentes columnas los convierte en outliers.

Vamos a graficar estos 4 outliers.
```{r C1_5b}
MiPlot_Univariate_Outliers(mydata.numeric, 
indices.de.outliers.multivariantes.MCD.pero.no.1variantes, 
"Outliers multivariantes pero no 1 variantes")
```

Vamos a realizarlo para cada uno por separado:

- S2
```{r C1_5b2}
MiPlot_Univariate_Outliers(mydata.numeric, 
2, 
"Outliers multivariante S2")
```

- S27
```{r C1_5c}
MiPlot_Univariate_Outliers(mydata.numeric, 
27, 
"Outliers multivariante S27")
```

- S124
```{r C1_5d}
MiPlot_Univariate_Outliers(mydata.numeric, 
124, 
"Outliers multivariante S124")
```

- S129
```{r C1_5e}
MiPlot_Univariate_Outliers(mydata.numeric, 
129, 
"Outliers multivariante S129")
```


# MULTIVARIATE STATISTICAL OUTLIERS -> LOF 

DetecciÃ³n de Outliers multivariantes segÃºn el mÃ©todo LOF.

```{r D1_1}
mis.datos.numericos <- mydata.numeric.backup
mis.datos.numericos.normalizados <- mydata.numeric.scaled.backup

corr.plot(mis.datos.numericos[,3], mis.datos.numericos[,4]) 
MiBiplot(mis.datos.numericos)
```



## DISTANCE BASED OUTLIERS (LOF)
```{r D1_2}
numero.de.vecinos.lof = 10
lof.scores <- lofactor(mis.datos.numericos.normalizados, numero.de.vecinos.lof)
plot(lof.scores)
```

EtablecÃ­ en 10 el nÃºmero de vecinos a considerar para el calculo de los scores de LOF.

La funciÃ³n lofactor devuelve un vector con los scores de LOF de todos los registros

Asumimos que los valores con un score LOF >= 1.5 son outliers.

```{r D1_2b}
numero.de.outliers = sum(lof.scores >= 1.5)
```

Hay `r sum(lof.scores >= 1.5)` outliers de acuerdo al score LOF, considerando outliers aquellos con un score LOF >= 1.5.

```{r D1_2c}
indices.de.lof.outliers.ordenados <- sort(lof.scores, index.return = TRUE, 
                                          decreasing = TRUE)$ix
indices.de.lof.top.outliers <- indices.de.lof.outliers.ordenados[1:numero.de.outliers]
indices.de.lof.top.outliers.reformat <- paste("S", 
                                              indices.de.lof.top.outliers, sep = "")
is.lof.outlier <- row.names(mis.datos.numericos) %in% 
  indices.de.lof.top.outliers.reformat
MiBiPlot_Multivariate_Outliers(mis.datos.numericos.normalizados, 
                               is.lof.outlier, "Biplot outliers")
```

Obtuve el indice de los outliers y luego grafique un biplot. Hay algunos valores como S8, S348, S58, S266 que no parecen ser outliers univariantes. Lo podemos chequear.


```{r D1_3}
vector.claves.outliers.IQR.en.alguna.columna <- 
  vector_claves_outliers_IQR_en_alguna_columna(mis.datos.numericos)
vector.es.outlier.IQR.en.alguna.columna <- 
  vector_es_outlier_IQR_en_alguna_columna(mis.datos.numericos)
MiBiPlot_Multivariate_Outliers(mis.datos.numericos.normalizados, 
                               vector.es.outlier.IQR.en.alguna.columna, 
                               "Biplot outliers IQR en alguna columna")
indices.de.outliers.multivariantes.LOF.pero.no.1variantes <- 
  setdiff(indices.de.lof.top.outliers,
vector.claves.outliers.IQR.en.alguna.columna)
indices.de.outliers.multivariantes.LOF.pero.no.1variantes
```

266 es el valor que no es un outlier univariante y si es un outlier LOF. Se corresponde a la muestra S266.

# MULTIVARIATE STATISTICAL OUTLIERS. CLUSTERING OUTLIERS 

DetecciÃ³n de Outliers multivariantes segÃºn los mÃ©todos basados en clustering.

```{r D2_1}
numero.de.outliers   = 5
numero.de.clusters   = 2

set.seed(2)  # Para establecer la semilla para la primera iteraci?n de kmeans
```

## kmeans
```{r D2_2}
modelo.kmeans <- kmeans(mis.datos.numericos.normalizados, centers = numero.de.clusters)
indices.clustering.pima <- modelo.kmeans$cluster
centroides.normalizados.pima <- modelo.kmeans$centers
indices.clustering.pima
centroides.normalizados.pima
```

Se realizo un clustering con k-means con un parÃ¡metro de k = `r numero.de.clusters`. Se obtuvieron las asignaciones de a que grupo pertenece cada valor en la variable _indices.clustering.pima_, y los centroides de cada grupo en la variable _centroides.normalizados.pima_.



```{r D2_4}
# FunciÃ³n para calcular distancia euclÃ­dea a los centroides
distancias_a_centroides = function (datos.normalizados, 
indices.asignacion.clustering, 
datos.centroides.normalizados){

sqrt(rowSums(   (datos.normalizados - 
                   datos.centroides.normalizados[indices.asignacion.clustering,])^2   ))
}

dist.centroides.pima <- distancias_a_centroides(mis.datos.numericos.normalizados, 
indices.clustering.pima,
centroides.normalizados.pima)

top.outliers.pima <- order(dist.centroides.pima, decreasing = TRUE)[1:numero.de.outliers]
top.outliers.pima

```

Se calculo la distancia de cada valor, al centroide del grupo al que fue asignado en el proceso de clustering. La distancia calculada es la **distancia euclÃ­dea**.
Luego se obtuvieron los top outliers, previamente se definio que se considerarÃ­an como outliers los `r numero.de.outliers` valores mÃ¡s alejados del centroide de su cluster. Los Ã­ndices de los outliers son los siguientes `r top.outliers.pima`.

```{r D2_5}
# Funcion que automatiza la bÃºsqueda de outliers
top_clustering_outliers <- function(datos.normalizados, 
indices.asignacion.clustering, 
datos.centroides.normalizados, 
numero.de.outliers) {

dist.centroides <- distancias_a_centroides(datos.normalizados, 
indices.asignacion.clustering,
datos.centroides.normalizados)

top.outliers <- order(dist.centroides, decreasing = TRUE)[1:numero.de.outliers]
res <- list(indices = top.outliers, distancias = dist.centroides[top.outliers])
}

```


```{r D2_6}
top.outliers.kmeans <- top_clustering_outliers(mis.datos.numericos.normalizados,
indices.clustering.pima,
centroides.normalizados.pima,
numero.de.outliers)

top.outliers.kmeans$indices
top.outliers.kmeans$distancias
```

La funciÃ³n top_clustering_outliers automatiza la bÃºsqueda de outliers de acuerdo al mÃ©todo de clustering.
Esta funciÃ³n devuelve una lista con los Ã­ndices y las distancias a sus centroides de los outliers. Esta informaciÃ³n la imprimimos por pantalla.


```{r D2_7}
numero.de.datos   = nrow(mis.datos.numericos)
is.kmeans.outlier = rep(FALSE, numero.de.datos) 
is.kmeans.outlier[top.outliers.kmeans$indices] = TRUE
# is.kmeans.outlier[top.outliers.kmeans.distancia.relativa] = TRUE


BIPLOT.isOutlier             = is.kmeans.outlier
# BIPLOT.cluster.colors        = c("blue","red","brown")     # Tantos colores como diga numero.de.clusters
BIPLOT.cluster.colors        = c("blue","red")     # Tantos colores como diga numero.de.clusters
BIPLOT.asignaciones.clusters = indices.clustering.pima
MiBiPlot_Clustering_Outliers(mis.datos.numericos, "K-Means Clustering Outliers")

```

GenerÃ© un vector booleano indicando para cada valor si es un outlier por el mÃ©todo de clustering o no. Luego setee unos parÃ¡metros de forma global para ejecutar la funcion MiBiPlot_Clustering_Outliers que grafica un biplot de los outliers identificados por el mÃ©todo de clustering.
Se puede ver marcados con una x los datos que se consideran outliers.

```{r D2_8}
mis.datos.medias <- colMeans(mis.datos.numericos)
mis.datos.desviaciones <- apply(X = mis.datos.numericos, MARGIN = 2, FUN = sd)
aux1 <- sweep(centroides.normalizados.pima, 2, mis.datos.desviaciones, FUN="*")
centroides.valores <- sweep(aux1, 2, mis.datos.medias, FUN="+")
centroides.valores
```

A partir de los datos normalizados, "revertimos" el proceso de normalizaciÃ³n para obtener los valores originales de los centroides de los `r numero.de.clusters` clusters que obtuvimos con k-means.


```{r D2_9}
top_clustering_outliers_distancia_mahalanobis = function(datos,
                                                         indices.asignacion.clustering,
                                                         numero.de.outliers){

  cluster.ids = unique(indices.asignacion.clustering)
  k           = length(cluster.ids)
  seleccion   = sapply(1:k, function(x) indices.asignacion.clustering == x)


  # Usando medias y covarianzas:
  # lista.matriz.de.covarianzas   = lapply(1:k, function(x) cov(mis.datos.numericos[seleccion[,x],]))
  # lista.vector.de.medias        = lapply(1:k, function(x) colMeans(mis.datos.numericos[seleccion[,x],]))


  # Usando la estimaci?n robusta de la media y covarianza: (cov.rob del paquete MASS:
  lista.matriz.de.covarianzas   = 
    lapply(1:k, function(x) cov.rob(mis.datos.numericos[seleccion[,x],])$cov)
  lista.vector.de.medias        = 
    lapply(1:k, function(x) cov.rob(mis.datos.numericos[seleccion[,x],])$center)


  mah.distances   = lapply(1:k,
                           function(x) mahalanobis(mis.datos.numericos[seleccion[,x],],
                                                   lista.vector.de.medias[[x]],
                                                   lista.matriz.de.covarianzas[[x]]))

  todos.juntos = unlist(mah.distances)
  todos.juntos.ordenados = names(todos.juntos[order(todos.juntos, decreasing=TRUE)])
  indices.top.mah.outliers = as.numeric(todos.juntos.ordenados[1:numero.de.outliers])


  list(distancias = mah.distances[indices.top.mah.outliers]  , 
       indices = indices.top.mah.outliers)
}

top.clustering.outliers.mah = top_clustering_outliers_distancia_mahalanobis(mis.datos.numericos,
                                                                            indices.clustering.pima,
                                                                            numero.de.outliers)

numero.de.datos = nrow(mis.datos.numericos)
is.kmeans.outlier.mah = rep(FALSE, numero.de.datos)
is.kmeans.outlier.mah[top.clustering.outliers.mah$indices] = TRUE

BIPLOT.isOutlier             = is.kmeans.outlier.mah
BIPLOT.cluster.colors        = c("blue","red","brown")     # Tantos colores como diga numero.de.clusters
BIPLOT.asignaciones.clusters = indices.clustering.pima
MiBiPlot_Clustering_Outliers(mis.datos.numericos, "K-Means Clustering Outliers")

```

En este caso construimos una funciÃ³n que pare el calculo de cada punto a su centroide utiliza la distancia de Mahalanobis.

```{r D2_10}
top_clustering_outliers_distancia_relativa = function(datos.normalizados, 
                                                      indices.asignacion.clustering, 
                                                      datos.centroides.normalizados, 
                                                      numero.de.outliers){
  
  dist_centroides = distancias_a_centroides (datos.normalizados, 
                                             indices.asignacion.clustering, 
                                             datos.centroides.normalizados)
  
  cluster.ids = unique(indices.asignacion.clustering)
  k           = length(cluster.ids)
  
  distancias.a.centroides.por.cluster    = 
    sapply(1:k , function(x) dist_centroides [indices.asignacion.clustering  == cluster.ids[x]])
  
  distancias.medianas.de.cada.cluster    = 
    sapply(1:k , function(x) median(dist_centroides[[x]]))
  
  todas.las.distancias.medianas.de.cada.cluster  =  
    distancias.medianas.de.cada.cluster[indices.asignacion.clustering]
  ratios = dist_centroides   /  todas.las.distancias.medianas.de.cada.cluster
  
  indices.top.outliers = order(ratios, decreasing=T)[1:numero.de.outliers]
  
  list(distancias = ratios[indices.top.outliers]  , indices = indices.top.outliers)
}



top.outliers.kmeans.distancia.relativa = 
  top_clustering_outliers_distancia_relativa(mis.datos.numericos.normalizados, 
    indices.clustering.pima, 
    centroides.normalizados.pima, 
    numero.de.outliers)


cat("?ndices de los top k clustering outliers (k-means, usando distancia relativa)")
top.outliers.kmeans.distancia.relativa$indices 
cat("Distancias a sus centroides de los top k clustering outliers (k-means, usando distancia relativa)")
top.outliers.kmeans.distancia.relativa$distancias

```

